TODO: train a model on the MNIST dataset
 -> the current config only has one epoch on it so make sure to change that
TODO: evaluate the newly trained model with the eval script
    FIXME: the bhatt kernel broke when I was running the eval:
    ------------------------------------------------------------------------------------
    eval_model.py 81 <module>
    main(config_path=Path(args.config))

    eval_model.py 66 main
    results = prob_evaluator(model=model, data_module=datamodule)

    _contextlib.py 116 decorate_context
    return func(*args, **kwargs)

    probabilistic_evaluator.py 126 __call__
    cce_vals, grid, targets, image_paths = self.compute_cce(

    probabilistic_evaluator.py 206 compute_cce
    cce_vals = compute_mcmd_torch(

    metrics.py 224 compute_mcmd_torch
    K_Y = y_kernel(y, y)

    kernels.py 135 bhattacharyya_kernel
    raise ValueError(

    ValueError:
    The rows of x or x_prime do not sum to 1, so the Bhattacharrya kernel is not applicable.
    ------------------------------------------------------------------------------------
    I think this might be a bit annoying to fix, I am guessing we need to one-hot encode the labels for the data.
    In the compute_cce() method I think we should be able to one hot the y_prime tensor (the one returned from the _get_samples_for_mcmd() on line 191).
    Might also need to softmax the y tensor so that the rows add up to one. Might need to ask Spencer about this one too.
TODO: get some example images of when the CCE is good vs bad from the data
 -> this might be kinda annoying, the MNIST images aren't actually in image files
    they're in those -ubyte files so I think they are just stored as bytes
